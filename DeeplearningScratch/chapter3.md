# 신경망

__가중치를 설정 작업은 사람이 수동으로 해야한다__ 하지만 신경망은 이것을 해결해줌.

신경망의 중요한 성질은 __가중치 매개변수의 적절한 값을 데이터로부터 자동으로 학습하는 능력__

## 퍼셉트론에서 신경망으로

신경망을 예로 들때 입력층, 은닉층, 출력층이 있으며, 은닉층은 숨겨져 있기때문에 은닉층임. 참고로 은닉층이 2개 이상인 신경망 구조를 딥러닝이라 __부를 수도__ 있음.

퍼셉트론에 편향을 명시하면 기존 퍼셉트론 모형에 가중치가 b 이고 입력이 1인 뉴런이 추가됨.

기존 퍼셉트론 식을 다음과 같은 간결한 형태로 다시 작성할 수 있음.
![Imgur](http://i.imgur.com/t7M8d7Q.png)

## 활성화 함수의 등장
__h(x)__ 를 활성화 함수(activation function), 입력신호의 총합이 활성화를 일으키지를 정하는 역할을 함.

위의 식을 다 시 써보면 다음과 같이 된다. <br>
a = b + w1x1 + w2x2 [^1] <br>
y = h(a)

가중치가 달린 입력 신호와 편향의 총합을 계산하고, 이를 a 라 함. a를 함수 h()에 넣어 y를 출력하는 흐름. 그림 3-4 참고

이 책에선 __뉴런__과 __노드__를 같은 의미로 사용함.


> 단순 퍼셉트론은 단층 계단 함수(임계값을 경계로 출력이 바뀌는 함수)를 활성화 함수로 사용한 모델

> 다층 퍼셉트론은 신경망(여러 층으로 구성되고 시그모이드 함수 등의 매끈함 활성화 함수를 사용하는 모델)을 가리킴
##  활성화 함수
활성화함수는 임계값을 경계로 출력이 바뀌는데, 이런 함수를 계단 함수(step function)이라 함.

퍼셉트론은 __이미 계단함수를 채용__! 활성화 함수를 계단 함수에서 __다른 함수로 변경__ 하는 것이 신경망의 세계로 나아가는 열쇠!
### 시그모이드 함수

h(x) = 1 / 1 + exp(-x)

신경망에서는 활성화 함수로 시그모이드 함수를 이용하여 신호를 변환하여 뉴런에 전달.

[^1] : 책을 자세히 보면 + 가 아니라 =+ 다.  