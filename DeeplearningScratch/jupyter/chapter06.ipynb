{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 학습 관련 기술\n",
    "\n",
    "- 매개변수의 최적화 방법\n",
    "- 가중치 매개변수 초깃값\n",
    "- 하이퍼파라미터 설정방법\n",
    "\n",
    "### 오버피팅의 대응책\n",
    "\n",
    "- 가중치 감소\n",
    "- 드롭아웃\n",
    "\n",
    "### 매개변수의 갱신 방법\n",
    "- 확률적 경사 하강법(SGD) 다시 보기\n",
    "- 모멘텀(Momentum)\n",
    "- AdaGrad\n",
    "- Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률적 경사하강법(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        \"\"\"lr은 학습률\"\"\"\n",
    "        self.lr = lr\n",
    "        \n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ W \\rightarrow W - \\eta\\frac{\\delta L}{\\delta W}  $$\n",
    "\n",
    "\n",
    "W는 갱신할 가중치 매개변수, 우변의 편미분은 W에 대한 손실함수의 기울기, 에타는 학습률이다. SGD에는 단점이 있는데 학습이 비효율적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient Descent Optimization Algorithms at Long Valley](http://i.imgur.com/2dKCQHh.gif?1)\n",
    "\n",
    "![Gradient Descent Optimization Algorithms at Saddle Point](http://i.imgur.com/NKsFHJb.gif?1)\n",
    "\n",
    "![Gradient Descent Optimization Algorithms at Beale's Function](http://i.imgur.com/pD0hWu5.gif?1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모멘텀\n",
    "\n",
    "$$ \n",
    "v \\leftarrow \\alpha v - \\eta \\frac{\\delta L}{\\delta W} \\\\\n",
    "W \\leftarrow W + v \n",
    "$$\n",
    "\n",
    "V는 물리에서 말하는 속도에 해당한다\n",
    "\n",
    "\n",
    "참고문헌에서 본 코드로 보면 간단하다\n",
    "SGD(Vanilla update)\n",
    "```python\n",
    "x += - learning_rate * dx \n",
    "```\n",
    "\n",
    "Momentum update\n",
    "```python\n",
    "v = mu * v - learning_rate * dx # integrate velocity\n",
    "x += v # integrate position\n",
    "```\n",
    "\n",
    "각각의 매개변수 갱신방법에 대한 그래프 모양은 위의 그림을 참고하도록 하자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "\n",
    "    \"\"\"모멘텀 SGD\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():                                \n",
    "                self.v[key] = np.zeros_like(val)\n",
    "                \n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] \n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad\n",
    "신경망 학습에서는 당연하게도 학습률이 중요하다. 너무 작으면 학습시간이 길어지고, 크면 발산하여 올바른 학습을 할 수 없기 때문. 이를 해결하는 간단한 방법은 일괄적으로 낮추는 것.\n",
    "\n",
    "AdaGrad는 개별 매개변수에 adative하게 학습률을 조정하여 학습을 진행한다\n",
    "\n",
    "$$ h \\leftarrow h + \\frac{\\partial L}{\\partial W} \\odot \\frac{\\partial L}{\\partial W} $$\n",
    "$$ W \\leftarrow W + \\eta \\frac{1}{\\sqrt{h}} \\frac{\\partial L}{\\partial W}  $$\n",
    "\n",
    "h라는 새로운 변수가 나오는데, 기존 기울기 값을 제곱하여 더해줌 (\\odot은 행렬의 원소별 곱셈을 의미함), 매개변수를 갱신할때 \\frac{1}{\\sqrt{h}}를 곱해 학습률을 조정함\n",
    "\n",
    "즉 AdaGrad는 과거의 기울기를 제곱하여 계속 더해간다. 그래서 학습을 진행할 수록 강도가 약해짐.\n",
    "\n",
    "RMSProp은 AdaGrad의 단점을 개선한 방법. 먼 과거의 기울기는 서서이 잊고 새로운 기울기 정보를 크게 반영한다. 이를 지수이동평균이라 하는데, 이것 또한 위에 그림이 있으니 참고하도록 하자.\n",
    "\n",
    "```python\n",
    "# RMSProp을 코드로 표현\n",
    "cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```\n",
    "참고문헌의 설명에 따르면.. \n",
    "> decay_rate는 초모수이고 보통 [0.9, 0.99, 0.999] 중 하나의 값을 취한다. 주목할 점은 += 업데이트는 Adagrad와 동등하지만, cache가 “어디선가 샌다”. 따라서 RMSProp은 여전히 각 웨이트값을 (그것의 과거 그라디언트) 값으로) 조정하여 성분별로 실질 학습속도를 비슷하게 만드는 효과는 갖고 있지만, Adagrad처럼 학습 속도가 단조적으로 줄지는 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "\n",
    "    \"\"\"AdaGrad\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
    "\n",
    "\n",
    "class RMSprop:\n",
    "\n",
    "    \"\"\"RMSprop\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01, decay_rate = 0.99):\n",
    "        self.lr = lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.keys():\n",
    "            self.h[key] *= self.decay_rate\n",
    "            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam\n",
    "\n",
    "RMSProp과 AdaGrad를 합친것 같은 알고리즘. 다른 문서에서도 이렇게 설명하는 것으로 보인다. 하이퍼파라미터의 '편향 보정'이 진행된다는 것이 특징!\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Adam을 코드로 간단히 표현\n",
    "m = beta1*m + (1-beta1)*dx\n",
    "v = beta2*v + (1-beta2)*(dx**2)\n",
    "x += - learning_rate * m / (np.sqrt(v) + eps)\n",
    "```\n",
    "참고문헌의 설명에 따르면..\n",
    "> 업데이트는 RMSProp의 업데이트 방식과 정확히 같아 보이는데, 그냥 (노이즈가 껴있을 수도 있는) 그라디언트 dx 대신에 “안정화된” 버전인 m이 사용되었다는 점이 다르다. 논문에 따르면 추천되는 초모수값들은 eps = 1e-8, beta1 = 0.9, beta2 = 0.999이다. 실전에서 Adam은 기본 알고리즘으로 추천되고 있고, 가끔은 RMSProp보다 조금 더 잘 하기도 한다. 그러나 SGD+Nesterov Momentum도 대안으로 해볼만 하다. Adam 업데이트 절차에는 편향 보정(bias correction) 매커니즘이 반영되어 있는데, 벡터 m,v가 나중에 완벽하게 “워밍업” 되기 전에 (iteration의 처음 몇 스텝에서) 초기화되어 0에 편향되어 있다는 점을 보상하기 위해서이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어느 갱신방법을 이용할 것인가? 라는 챕터인데. 책에서는 SGD를 쓴다고 했다. NGD(SGD 변형)와 Adam을 주로 많이 쓴다.\n",
    "실제 MNIST 데이터 셋으로 갱신방법을 비교하면 SGD가 가장 느리다. 물론 문제에 따라 다르겠지만 일반적으로 느릴것같다.\n",
    "\n",
    "## 가중치의 초깃값\n",
    "\n",
    "초깃값을 0으로 하면 학습이 제대로 이루어지지 않음.가중치를 작게 만들고 싶으면, 초기값도 작은 값부터 시작해야한다. 지금까지 가중치의 초깃값은 정규분포에서 생성되는 값을 0.01배 한 값을 사용하였다. 즉, 표준편차가 0.01인 정규분포.\n",
    "\n",
    "예를 들어, 2층 신경망에서 첫 번째와 두 번채 층의 가중치가 0이라고 가정할 때, 순전파 입력치의 가중치가 0이기 때문에, 두번째 층의 뉴런에 모두 같은 값이 전달됩니다. 이렇게 되면, 역전파 시에 두 번째 층의 가중치가 모두 동일하게 갱신됩니다. 이는 가중치를 여러 개 쓰는 것을 의미없게 만듭니다.\n",
    "\n",
    "이를 막기 위해서는, 초깃값을 무작위로 설정해야함\n",
    "\n",
    "## 은닉층에서는 어떤일이?\n",
    "\n",
    "각 층의 활성화 값의 히스토그램을 확인하면 활성화 값이 0과 1에 치우쳐져 분포되어 있음. 활성화 함수나 초깃값을 바꿔서 실행해본결과 고르게 분포되어 있지 않다는 것을 알 수 있음. 이는 __표현력 제한 문제__에 빠져 있다는 뜻이된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU를 사용할 때의 가중치 초깃값\n",
    "\n",
    "Xavier 초깃값은 활성화 함수가 선형 것을 전제로 이끈 결과. 그렇기 때문에, ReLU를 사용할때는 ReLU에 특화된 초깃값을 이용하라고 권장. \n",
    "이를 He 초깃값이라고 하는데, 앞 노드가 n개일때, 표준편차가 \\sqrt\\frac{2}{n}인 정규분포를 사용하는 것.\n",
    "\n",
    "He 초깃값을 사용하면, 활성화 함수 결과값이 모든 층에 균일하게 분포되기 때문에, 층이 깊어져도 적절한 값이 나올 것으로 기대할 수 있음\n",
    "\n",
    "정리하면.. \n",
    "- 활성화 함수가 sigmoid나 tanh같이 S자 모양 곡선인 경우 : Xavier 초깃값이 적당함\n",
    "- 활성화 함수가 ReLU인 경우 : He\n",
    "\n",
    "활성화 값들을 잘 __제어__(표현력 제한 해결)해야 학습이 잘된다.(결과가 잘 나옴)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 정규화\n",
    "가중치의 초깃값을 적절히 설정하면 각 층의 활성화 값 분포가 적당히 퍼지면서 학습이 잘된다는 것을 확인할 수 있었다. 2015년에 나왔지만 가중치 초깃값 선택하는 것보다 결과가 잘 나와 이 방법을 많이 사용함.\n",
    "\n",
    "요약하면 다음과 같은 장점이 있다.\n",
    "\n",
    "- 학습을 빨리 진행할 수 있다. -> 중요하다\n",
    "- __초깃값에 크게 의존하지 않는다.__ -> 초깃값 결과에 따라 활성화 값이 다르기 때문\n",
    "- __오버피팅을 억제.__\n",
    "\n",
    "기본적인 아이디어는 행렬곱과 활성화 함수 처리과정 중간에, 배치 정규화 계층(Batch Norm)을 삽입하여, 활성화값이 적당히 분포되도록 조정하는 것이다.\n",
    "\n",
    "미니배치 단위로 정규화를 진행하는데, 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화한다. 수식은 다음과 같다.\n",
    "$$ \\mu_B \\leftarrow \\frac{1}{m} \\sum^{m}_{i=1} {x_i} $$\n",
    "\n",
    "$$ \\sigma^2_B \\leftarrow \\frac{1}{m} \\sum^{m}_{i=1} {x_i} \\left( x_i - \\mu_B \\right)^2 $$\n",
    "\n",
    "$$ \\hat{x}_i \\leftarrow \\frac{x_i - \\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미니배치 m개의 입력 데이터에 대해 평균과 분산을 구하고, 그 값을 가지고 어파인 출력값을 평균 0, 분산 1인 데이터로 정규화하는 식입니다.\n",
    "\n",
    "또한 배치 정규화 계층마다, 정규화된 데이터에 확대와 이동 변환을 수행합니다. 수식으로는 다음과 같다.\n",
    "$$ y_i \\leftarrow \\gamma \\hat{x}_i + \\beta $$\n",
    "\n",
    "평균과 분산을 구한 다음, 입력 데이터를 평균이 0, 분산이 1이 되게 정규화함. 엡실론은 0으로 나누는 것을 방지하는 역할(세번째 식)\n",
    "\n",
    "감마가 확대(scale)를 베타가 이동(shift)를 수행함. 처음에는 각각 1과 0에서 시작. 이는 감마 1일 경우 1배 확대를 의미. 베타가 0이라는 것은 이동하지 않는다는 것을 의미한다. 학습하면서 적합한 값으로 조정해나간다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 바른 학습을 위해\n",
    "오버피팅의 경우 두 경우에 일어난다 \n",
    "- 매개변수가 많고 표현력이 높은 모델\n",
    "- 훈련 데이터가 적음\n",
    "\n",
    "오버피팅의 경우 훈련데이터를 사용하여 측정한 정확도는 100%에 가깝게 나타날 수 있지만, 시험데이터에 대해선 큰 차이를 보일 수 있다. 즉 훈련데이터에만 적응해버리고 실제에는 대응하지 못하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  가중치 감소\n",
    "\n",
    "학습 과정에서 큰 가중치에 대해서는 큰 페널티를 부과하여 오버피팅을 억제하는 방법. 신경망 학습의 목적은 __손실 함수의 값을 줄이는 것__이었음. 이 때, 가중치의 제곱(L2 법칙)을 손실 함수에 더하면 가중치가 커지는 것을 억제할 수 있다.\n",
    "\n",
    "가중치를 W라고 하면\n",
    "\n",
    "1. 가중치 감소를 구한다 : 1/2 \\lambda W^2\n",
    "2. 손실 함수 <- 손실함수 + 1/2 \\lambda W^2\n",
    "    여기서 람다는 정규화의 세기를 조정하는 하이퍼파라미터. 람다를 크게 설정할수록 큰 가중치에 대한 패널티가 커집니다.\n",
    "    앞의 1/2은 미분결과인 \\lambda W를 조정하는 상수\n",
    "가중치 감소는 모든 가중치 각각의 손실 함수에 1/2 \\lambda W^2를 더합니다. 따라서 가중치의 기울기를 구하려면, 오차역전파법에 따른 결과에 정규화 항을 미분한 \\lambda W를 더합니다.\n",
    "\n",
    "\\lambda를 0.1로 가중치 감소를 적용하면 __여전히 정확도에는 차이가 있을 수 있다.__ __오버피팅을 억제__하는데에는 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 법칙\n",
    "L2 법칙은 각 원소(가중치)의 제곱들을 더한것에 해당. L1과 L MAX 법칙도 있다. \n",
    "- L1 법칙 : 절댓값의 합\n",
    "- LMax 법칙 : 각 원소의 절댓값 중 가장 큰 것에 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃(Dropout)\n",
    "\n",
    "신경망 모델이 복잡해지면 가중치 감소만으로 대응하기 어려워짐. 위에서 강조한 문구에서 봤듯이 여전히 정확도에 차이가 있을 수 있음.\n",
    "\n",
    "드롭아웃은 뉴런을 임의로 삭제하면서 학습하는 방법. -> 훈련때, __훈련하면서__ 은닉층의 뉴련을 __무작위로 골라 삭제__한다. 시험할때는 각 뉴런에 출력에 훈련때 삭제한 비율을 곱하여 출력한다.\n",
    "\n",
    "코드에서 중요한 부분은, 훈련시에 순전파 때마다 `self.mask`에 삭제할 뉴런을 `False`로 표시한다는 것. self.mask는 x와 같은 배열을 무작위로 생성하고\n",
    "`dropout_ratio`보다 큰 원소만 `True`로 설정한다. 즉, __순전파 때 통과한 뉴런__은 역전파 때도 신호를 통과하고, 통과하지 못한 뉴런은 역전파 때도 통과를 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    \"\"\"\n",
    "    http://arxiv.org/abs/1207.0580\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:265, train acc:0.593333333333, test acc:0.5069 ===\n",
      "train loss:1.21242923261\n",
      "train loss:1.09799599006\n",
      "train loss:1.14916591288\n",
      "=== epoch:266, train acc:0.59, test acc:0.5084 ===\n",
      "train loss:1.29893413033\n",
      "train loss:1.20609384777\n",
      "train loss:1.32107256127\n",
      "=== epoch:267, train acc:0.6, test acc:0.5116 ===\n",
      "train loss:1.27398699263\n",
      "train loss:1.18790324154\n",
      "train loss:1.19147481293\n",
      "=== epoch:268, train acc:0.6, test acc:0.5126 ===\n",
      "train loss:1.1653515149\n",
      "train loss:1.18439729692\n",
      "train loss:1.17710308736\n",
      "=== epoch:269, train acc:0.603333333333, test acc:0.5129 ===\n",
      "train loss:1.08449885861\n",
      "train loss:1.223138175\n",
      "train loss:1.12488930364\n",
      "=== epoch:270, train acc:0.603333333333, test acc:0.5124 ===\n",
      "train loss:1.20181991477\n",
      "train loss:1.35231642265\n",
      "train loss:1.27432255484\n",
      "=== epoch:271, train acc:0.606666666667, test acc:0.5185 ===\n",
      "train loss:1.1934731914\n",
      "train loss:1.1777186678\n",
      "train loss:1.08532512483\n",
      "=== epoch:272, train acc:0.61, test acc:0.5207 ===\n",
      "train loss:1.15013578917\n",
      "train loss:1.22575466086\n",
      "train loss:1.16121801946\n",
      "=== epoch:273, train acc:0.613333333333, test acc:0.5219 ===\n",
      "train loss:1.12316507414\n",
      "train loss:1.12732069572\n",
      "train loss:1.1617590277\n",
      "=== epoch:274, train acc:0.606666666667, test acc:0.5185 ===\n",
      "train loss:1.13083338477\n",
      "train loss:1.2108036362\n",
      "train loss:1.20501908369\n",
      "=== epoch:275, train acc:0.606666666667, test acc:0.5195 ===\n",
      "train loss:1.21708686764\n",
      "train loss:1.1472450804\n",
      "train loss:1.23954116812\n",
      "=== epoch:276, train acc:0.61, test acc:0.5217 ===\n",
      "train loss:1.10115562269\n",
      "train loss:1.3528246637\n",
      "train loss:1.17754697848\n",
      "=== epoch:277, train acc:0.606666666667, test acc:0.52 ===\n",
      "train loss:1.18818411621\n",
      "train loss:1.1894289528\n",
      "train loss:1.19755097032\n",
      "=== epoch:278, train acc:0.606666666667, test acc:0.5212 ===\n",
      "train loss:1.3349185551\n",
      "train loss:1.05109408374\n",
      "train loss:1.20443486314\n",
      "=== epoch:279, train acc:0.603333333333, test acc:0.5206 ===\n",
      "train loss:1.04609598064\n",
      "train loss:1.15224840884\n",
      "train loss:1.19024181825\n",
      "=== epoch:280, train acc:0.603333333333, test acc:0.5198 ===\n",
      "train loss:1.17948939882\n",
      "train loss:1.2588290893\n",
      "train loss:1.18857085365\n",
      "=== epoch:281, train acc:0.6, test acc:0.5185 ===\n",
      "train loss:1.03878183064\n",
      "train loss:1.25195978961\n",
      "train loss:1.17246360923\n",
      "=== epoch:282, train acc:0.616666666667, test acc:0.5256 ===\n",
      "train loss:1.15911424408\n",
      "train loss:1.33826058067\n",
      "train loss:1.07182648792\n",
      "=== epoch:283, train acc:0.62, test acc:0.5273 ===\n",
      "train loss:1.25054009444\n",
      "train loss:1.16943621361\n",
      "train loss:1.13072917417\n",
      "=== epoch:284, train acc:0.626666666667, test acc:0.5286 ===\n",
      "train loss:1.18714415835\n",
      "train loss:1.28856304485\n",
      "train loss:1.19362927521\n",
      "=== epoch:285, train acc:0.626666666667, test acc:0.5298 ===\n",
      "train loss:1.09532420026\n",
      "train loss:1.13214125118\n",
      "train loss:1.01039084723\n",
      "=== epoch:286, train acc:0.63, test acc:0.5333 ===\n",
      "train loss:1.21286429421\n",
      "train loss:0.990249634166\n",
      "train loss:1.12087798774\n",
      "=== epoch:287, train acc:0.643333333333, test acc:0.5349 ===\n",
      "train loss:1.0445427857\n",
      "train loss:1.19366001684\n",
      "train loss:1.07067046841\n",
      "=== epoch:288, train acc:0.636666666667, test acc:0.5331 ===\n",
      "train loss:1.11097121505\n",
      "train loss:1.09895103648\n",
      "train loss:1.14757776103\n",
      "=== epoch:289, train acc:0.636666666667, test acc:0.5327 ===\n",
      "train loss:1.07403293223\n",
      "train loss:1.03118904066\n",
      "train loss:1.12097520937\n",
      "=== epoch:290, train acc:0.623333333333, test acc:0.5335 ===\n",
      "train loss:1.08491634271\n",
      "train loss:1.11520441298\n",
      "train loss:1.15396596373\n",
      "=== epoch:291, train acc:0.62, test acc:0.5269 ===\n",
      "train loss:1.07364859605\n",
      "train loss:1.09862679427\n",
      "train loss:1.04511010091\n",
      "=== epoch:292, train acc:0.61, test acc:0.5274 ===\n",
      "train loss:1.04855650133\n",
      "train loss:1.07175649265\n",
      "train loss:0.915675769524\n",
      "=== epoch:293, train acc:0.63, test acc:0.5319 ===\n",
      "train loss:1.07589214142\n",
      "train loss:1.21036342333\n",
      "train loss:1.05781279786\n",
      "=== epoch:294, train acc:0.636666666667, test acc:0.5368 ===\n",
      "train loss:1.14576955422\n",
      "train loss:1.06157668613\n",
      "train loss:1.00215879153\n",
      "=== epoch:295, train acc:0.636666666667, test acc:0.5348 ===\n",
      "train loss:1.01017627889\n",
      "train loss:1.09367464335\n",
      "train loss:1.0658325531\n",
      "=== epoch:296, train acc:0.63, test acc:0.5314 ===\n",
      "train loss:0.952152142336\n",
      "train loss:0.994015873305\n",
      "train loss:1.11435401259\n",
      "=== epoch:297, train acc:0.633333333333, test acc:0.5333 ===\n",
      "train loss:1.04882190178\n",
      "train loss:1.06350271592\n",
      "train loss:0.972152084379\n",
      "=== epoch:298, train acc:0.636666666667, test acc:0.5334 ===\n",
      "train loss:1.01727243757\n",
      "train loss:0.97141701792\n",
      "train loss:1.12641362308\n",
      "=== epoch:299, train acc:0.646666666667, test acc:0.542 ===\n",
      "train loss:1.08002454567\n",
      "train loss:1.15254589955\n",
      "train loss:1.16392585596\n",
      "=== epoch:300, train acc:0.636666666667, test acc:0.5416 ===\n",
      "train loss:0.961531109447\n",
      "train loss:1.18276068006\n",
      "train loss:1.05149918513\n",
      "=== epoch:301, train acc:0.65, test acc:0.5414 ===\n",
      "train loss:0.93433828599\n",
      "train loss:0.988747776775\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5448\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiLi8/8B0wtvhXhSmf8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10948add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 보면,\n",
    "- 드롭아웃 적용시, 훈련 데이터에 대한 정확도가 1.0에 도달하지 못했다.\n",
    "- __훈련 데이터와 실제 데이터 사이의 정확도 차이가 줄었다.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블 학습?\n",
    "\n",
    "앙상블 학습은 개별적으로 학습시킨 __여러 모델의 출력을 평균 내어 추론하는 방식__이다.\n",
    "\n",
    "아이디어는 데이터 집합에 대해 성능이 가장 좋은 학습 모델을을 고르는 것이 아니라 여러가지 다양한 모델을 모두 이용해서 얻은 결과를 조합해보는 것. 다시 말해, 기계 학습의 분류 방법을 통해 여러개의 분류기를 생성하고, 그 예측을 결함합으로써 새로운 가설을 학습하는 방법이다.\n",
    "\n",
    "참고문헌에 따르면..\n",
    "> 학습 알고리즘을 조작하여 다양한 분류기를 생성한 후 다수결(Majority Voting)이나 가중치 투표(Weighted Voting)에 의하여 예측값을 결합한다. 이러한 앙상블 학습을 하는 대표적인 방법으로 부스팅(Boosting)과 배깅(Bagging)이 있다. 배깅과 부스팅은 학습 데이터를 샘플링하여 다양한 학습 데이터를 생성하며, 하나의 학습 알고리즘을 적용하여 다양한 분류기를 생성한다.\n",
    "하나의 데이터 세트에 다양한 학습 알고리즘을 적용하여 다양한 분류기를 생성하는 앙상블 학습 방법도 있다. 이럴 경우, 예측값을 결합하기 위해 투표보다는 좀 더 복잡한 방법을 사용하기도 한다. 대표적인 방법으로 스태킹(Stacking)이 있다. 스태킹은 다양한 학습 알고리즘을 이용하여 분류기를 생성하고 이 분류기들의 예측값을 결합하는 분류기를 추가로 학습한다.\n",
    "또 다른 방법으로는 전문가의 혼합(Mixture of  Experts) 방법이 있다. 이 방법은 각각의 분류기에 다른 지역을 할당하여 성능을 향상시키는 방법이다[4]. 이 방법에서는 각각의 분류기뿐만 아니라 분류기에 지역을 할당하기 위한 게이트 함수(Gating Function)도 학습해야 한다.\n",
    "\n",
    "정리하면 \n",
    "1. 훈련 집합의 조작(배깅, 부스팅)\n",
    "2. 입력 특징의 조작(랜덤 포레스트)\n",
    "3. 클래스 레이블의 조작\n",
    "4. 학습 알고리즘의 조작\n",
    "\n",
    "앙상블은 모델간 다양성이 있는 경우 더 좋은 결과를 낸다. 앙상블 학습은 조합하는 모델간의 다양성을 증진시키려고 한다고 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 적절한 하이퍼파라미터 값 찾기\n",
    "\n",
    "하이퍼파라미터는 다수 등장. 예를 들어, \n",
    "- 각 층의 뉴런 개수\n",
    "- 배치 크기\n",
    "- 매개변수 갱신 시의 학습률과 가중치 감소\n",
    "\n",
    "쉽게 말하면 __학습시 중요한 요소들__이다.\n",
    "\n",
    "### 하이퍼파라미터 최적화\n",
    "\n",
    "하이퍼파라미터 최적화의 핵심은, 하이퍼파라미터 ‘최적 값’이 존재하는 범위를 조금씩 줄여 가는 것.\n",
    "순서는\n",
    "1. 대략적인 범위를 설정\n",
    "2. 무작위로 하이퍼파라미터 값을 골라낸다(샘플링)\n",
    "3. 샘플링한 하이퍼파라미터 값을 가지고 학습하고, 검증 데이터로 정확도를 평가(에폭은 작게 설정)\n",
    "4. 정확도를 살피면서 2~3번을 여러 번 반복하여(100회 등) 최적값의 범위를 좁혀간다.\n",
    "범위는 __대략적__으로 지정하는 것이 효과적이다. 실제로도 0.001에서 1000사이와 같이, 10의 계승 단위로 범위를 지정합니다. 이를 로그 스케일로 지정한다고 한다.\n",
    "\n",
    "딥러닝 학습에는 오랜 시간이 걸립니다. 1~3번을 계속해서 반복해야 하기 때문에, 나쁠 듯한 값은 일찍 포기하는 것이 좋습니다. 그래서 에폭을 적게 하여 여러 1회 평가에 걸리는 시간을 단축하는 것이 효과적이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이즈 최적화 \n",
    "좀 더 세련된 기법이라고 한다. 참고문헌을 보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 최적화 구현하기 \n",
    "무작위로 추출한 값을 가지고 학습을 시작. 그 후에는 다양한 하이퍼파라미터 값으로 학습을 반복하여, 신경망에 좋을 거 같은 값이 어디에 존재하는지 관찰한다.\n",
    "\n",
    "```python\n",
    "weight_decay = 10 ** np.random.uniform(-8, -4) # 가중치 감소 계수를 10^-8~10^-4 \n",
    "lr = 10 ** np.random.uniform(-6, -2) # 학습률의 범위를 10^-6 ~ 10^-2\n",
    "```\n",
    "\n",
    "여러 번 학습을 한 후에, 학습이 잘 된 모델을 추출하여 그 때의 하이퍼파라미터 값을 확인한다.. 예를 들어, 학습이 잘 진행될 때의 학습률은 0.001~0.01 이고, 가중치 감소 계수는 10^−8, 10^−6 이라고 하면, 축소된 값을 가지고 다시 변수를 할당하여 학습을 반복한다. 이렇게 범위를 좁혀가다가, 특정 단계에서 최종 하이퍼파라미터 값을 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고하면 좋은 글들\n",
    "- [Gradient Descent Optimization Algorithms 정리](http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html)\n",
    "- [CS231n Convolutional Neural Networks for Visual Recognition](http://aikorea.org/cs231n/neural-networks-3/#sgd)\n",
    "- [CS231n Convolutional Neural Networks for Visual Recognition](http://aikorea.org/cs231n/optimization-1/)\n",
    "- [베이지안 최적화](http://sanghyukchun.github.io/99/#gp-with-noisy-data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
